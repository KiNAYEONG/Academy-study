2024.08.27.(화)
<비지도학습_사내식당이용률 예측>
- lambda 함수 사용
- 리스트 형태의 데이터를 문자열로 변경해주는 작업 진행 (TF - IDF 방식 활용을 위해)
- 불필요한 정보를 제거하기 위한 remove 함수 만듦.
>re.sub(찾고자하는 패턴, 바꾸고자하는 값, text)
>r'\([^)]*\)' : list 안에 닫는 괄호를 제외한(^) 모든 문자를 닫는 괄호가 나타나기 전까지 찾아주세요
>>*는 '모든'을 뜻하는 말인데 닫는 괄호'^)'가 나타나기 전까지 '모든' 문자를 지우기 위함.

-TF-IDF
> 텍스트 데이터 벡터화 도구인데 문자열의 빈도수에 기반한 중요도 확인할 수 있음.
> 문서 내 단어 빈도와 전체 문서에서의 희귀성을 반영한 가중치 계산
> 점수가 가장 높은 데이터 출력
>> top_n_idx = tfidf_df.iloc[0].argmax()
>최고점수의 메뉴를 추출하는 과정을 함수로 정의하여 한번에 실행
>> 
1.객체생성 
2.메뉴별 TF-IDF 점수 변환
3.변환한 점수 확인 위해 DataFrame으로 출력
4.각 메뉴별 TF-IDF 점수가 높은 단어를 추출 -> 함수화
5. lambda 식을 적용한 메인메뉴 추출

- groupby와 plot을 사용해 main 메뉴에 따른 석식계 수치 확인 및 시각화
- 불리언인덱싱을 사용해 조건에 맞는 데이터 추출
>전체데이터[조건]
>data[data['석식계'] == 0] # !=도 사용가능.

- 불필요한 컬럼 삭제
> data.drop(columns=['A'], inplace=True)

- 다시 정리해보는 인코딩
> 원핫인코딩 : 값의 우선순위의 의미가 없을 때 사용 -> 0 or 1의 값으로 변경
>레이블인코딩: 값의 우선순의가 존재 -> 우선순위가 높은 데이터에 높은 숫자를 매칭
>빈도수인코딩: 데이터의 빈도수로 대체
>>장점:범주형 데이터의 빈도를 반영함
>>단점:빈도가 같을 때 구분이 어려울수있음

-데이터 전처리
>스케일링: 우리의 데이터를 표준화된 범위로 변경
>>데이터 특성별로 데이터의 크기가 많이 다르게 되면 제대로 된 학습이 어려울 수 있음
>>스케이링을 통해서 데이터특성의 범위(분포)를 비슷하게 변경

-K-means
> 비슷한 샘플들끼리 군집 형성
> 쉽고 간결함
> 거리기반 알고리즘 속성의 개수가 많거나 스케일링이 되지 않은 경우 정확도가 떨어질수 있음
> 몇개의 군집을 선택해야 하는지 정확히 알 수 없음

- 최적의 클러스터 수 결정하는 방법
- 엘보우 기법
> 가장 완만해지는 k 수 찾기 -> 가장 효율적인 클러스터의 수를 의미
> 직관적이나, 엘보우 지점을 선택하는 과정에서 주관이 개입

- 클러스터의 개수 설정
ks = range(1,10) 








