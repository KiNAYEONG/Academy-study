20240830_텍스트마이닝 응용

# 학습목표
- 감성분석 모델링
- 감성분석이란? -> 사람의 감정, 기분 태도를 분석하는 기법
- 자연어 처리
- konlpy 패키지 내에 있는 다양한 형태소 분석기들을 사용
- konlpy: 한국어 자연어 처리를 위한 파이썬 패키지

# konply
# 1. 로컬컴퓨터에 환경설정(jdk,jpye)이 까다로워 컴퓨터마다 안될수도 있음 -> colab
# 2. konlpy 중 mecab 형태소분석기 -> 리눅스 운영체제에서 사용가능 -> colab 진행

# 위 두가지 이유로 자연어처리(형태소 분석, 토큰화 작업)은 colab에서 진행 

# colab에서 전처리 진행한 clan_morphs.pkl 파일 불러와서 실습 진행
import pickle
with open('data/clean_morphs.pkl','rb') as f: 
-> 읽어올거라서 rb임! read
clean_morphs = pickle.load(f)

# 구축된 단어사전 확인(CounterVectorizer) -> 유니크한 단어들이다!
cv.vocabulary_

# 단어사전을 기반으로 문장내의 단어 빈도를 측정!
result = cv.transform(sample_text2)

import sys
# 전체 칼럼 보기
np.set_printoptions(threshold=sys.maxsize)

# 단어사전에 문장별로 데이터 유무를 확인하고 싶다면? -> toarray()
result.toarray()[0] # 무슨 단어가 있는지 알 수 없는 상태 -> 데이터 프레임이 필요하다!
0과 1만 있음.

# 위에서 확인한 데이터를 DataFrame으로 만들어서 확인
df = pd.DataFrame([cv.vocabulary_.keys()], columns=cv.vocabulary_.values())

# 무슨 단어인지(제목) + 빈도수 동시에 확인하기 위해 concate 필요
result_df=df.sort_index(axis=1) 

# 두개 합칠거니까 리스트 형태로 만든다.
pd.concat([result_df, pd.DataFrame(result.toarray())]) 

# 토큰화된 데이터와 별점 데이터를 붙이기

# 리스트 형태로 되어있는 데이터를 별점과 concat 해주기 위해서 DataFrame으로 변경
# 리스트로 묶여있는 데이터를 문자열로 변경
clean_morphs2 = [' '.join(s) for s in clean_morphs] 
# 전체 데이터 대상으로 df 만들어줄거라서 한번 더 쓴 코드임.

# 열단위로 합칠거니까 axis = 1로 해줘야 함.
review_data = pd.concat([temp, naver_data['별점']], axis=1) 

# 별점이 5점이거나 4점인 데이터를 쓰기 위해 '|' 씀.
review_data[(review_data['별점'] == 5) | (review_data['별점'] == 4)]['리뷰']










