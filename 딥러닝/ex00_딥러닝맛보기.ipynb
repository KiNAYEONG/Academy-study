{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 단축키 사용법\n",
        "- 실행단축키\n",
        "  - ctrl + Enter: 실행 후 커서가 그대로 있음\n",
        "  - shift + Enter: 실행 후 커서 아래 셀로 이동\n",
        "\n",
        "- 마크다운 변환\n",
        "  - ctrl + m + m\n",
        "- 코드모드로 변환\n",
        "  - ctrl + m + y\n",
        "\n",
        "- 셀 아래 추가하기\n",
        "  - ctrl + m + b\n",
        "- 셀 위에 추가하기\n",
        "  - ctrl + m + a"
      ],
      "metadata": {
        "id": "mHnSNkUfsksm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 딥러닝 맛보기\n",
        "- 딥러닝이란?\n",
        "  - 인간의 신경망을 모방하여 학습하고 예측하는 기술\n",
        "  - 대량의 데이터에서 복잡한 패턴이나 규칙을 찾아내는 능력이 뛰어나다\n",
        "  - 머신러닝에 비해 유연한 사고를 한다\n",
        "  - 인간의 뉴런 == 딥러닝에서는 선형모델(y=wx+b)\n",
        "  - 주로 영상처리, 음성처리, 이미지처리 분야에 적용\n",
        "- tensorflow\n",
        "  - 구글이 만든 딥러닝 라이브러리\n",
        "- Keras\n",
        "  - tensorflow 위에서 동작하는 사용자 친화적 라이브러리\n"
      ],
      "metadata": {
        "id": "Zuh2VMtstASM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensorflow 버전 확인\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "# 코랩은 기본적으로 텐서플로우 설치되어있음\n",
        "# 설치버전 확인 이유 -> 딥러닝모델을 가져다 사용할 때 버전이 일치해야한다!\n",
        "# 오픈소스 사용시 버전 일치여부 확인! (2.17)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlNdnxKhtAqS",
        "outputId": "7565f8dc-cfc0-45ca-8500-fa2157fd1ebd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 -> 리눅스 환경\n",
        "# 리눅스 명령어를 사용하면 편함!\n",
        "!pwd # 현재 작업 디렉토리 확인 (print work directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMissjC5t2d0",
        "outputId": "a954a854-0a8b-4a91-8693-f9a1b97b1fbf"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/24.09.02 DeepLearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 작업 디렉토리 변경방법\n",
        "# %cd\n",
        "# %change directory -> ! 셀 실행시 적용, % 영구적 적용\n",
        "%cd \"/content/drive/MyDrive/Colab Notebooks/24.09.02 DeepLearning\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1TeQ1RntBfk",
        "outputId": "cef6e6a0-4d98-44d2-c4ee-95377570bf74"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/24.09.02 DeepLearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ycWmdBt5lQ",
        "outputId": "43e367c9-933c-45c1-dea6-81940722ff91"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/24.09.02 DeepLearning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ls -> 현재 폴더 안에 파일 list 확인\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmlEVkZLt6c1",
        "outputId": "7e2bb408-a34e-4a80-c527-49bb2180ed89"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  ex00_딥러닝맛보기.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 머신러닝과 딥러닝 모델 비교\n",
        "- 실습\n",
        "  - 동일한 데이터를 가지고 머신러닝, 딥러닝 모델링을 통해 차이점 알아보기\n",
        "  - 공부시간에 따른 학생의 수학성적을 예측하는 모델링(머신러닝 딥러닝)\n",
        "\n",
        "### 머신러닝과 딥러닝 모델의 차이점\n",
        "- 머신러닝\n",
        "  - 모델객체생성(완성된 객체 사용) -> 모델학습 -> 모델예측 -> 모델평가\n",
        "  - 완제품 로봇 - 팔정도만 움직일 수 있음(하이퍼파라미터 조절)\n",
        "\n",
        "- 딥러닝\n",
        "  - 모델객체생성(모델을 직접 구성_신경망 설계) -> 모델학습 -> 모델예측 -> 모델평가\n",
        "  - 조립식 로봇 / 레고 (우리가 구성하고자 하는 모양으로 구성 가능)\n",
        "  - 다양한 결과를 만들어낼 수 있음"
      ],
      "metadata": {
        "id": "eminbG4yt6aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 불러오기"
      ],
      "metadata": {
        "id": "MjklllQut6X0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "2Qj7x0cqt6V0"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data/student-mat.csv\", delimiter=';')\n",
        "data\n",
        "\n",
        "# 정답 레이블로 사용할 컬럼 : G3 (3학년 성적)\n",
        "# 3학년 성적을 학습 및 예측하는 모델링\n",
        "# 다양한 입력 특성(문제데이터) 중에서 1개 특성만 선택 진행 -> 공부시간(studytime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "NNYpt3nut6To",
        "outputId": "f2ef07df-2467-459c-9aec-e73e961bc922"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    school sex  age address famsize Pstatus  Medu  Fedu      Mjob      Fjob  \\\n",
              "0       GP   F   18       U     GT3       A     4     4   at_home   teacher   \n",
              "1       GP   F   17       U     GT3       T     1     1   at_home     other   \n",
              "2       GP   F   15       U     LE3       T     1     1   at_home     other   \n",
              "3       GP   F   15       U     GT3       T     4     2    health  services   \n",
              "4       GP   F   16       U     GT3       T     3     3     other     other   \n",
              "..     ...  ..  ...     ...     ...     ...   ...   ...       ...       ...   \n",
              "390     MS   M   20       U     LE3       A     2     2  services  services   \n",
              "391     MS   M   17       U     LE3       T     3     1  services  services   \n",
              "392     MS   M   21       R     GT3       T     1     1     other     other   \n",
              "393     MS   M   18       R     LE3       T     3     2  services     other   \n",
              "394     MS   M   19       U     LE3       T     1     1     other   at_home   \n",
              "\n",
              "     ... famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
              "0    ...      4        3      4     1     1      3        6   5   6   6  \n",
              "1    ...      5        3      3     1     1      3        4   5   5   6  \n",
              "2    ...      4        3      2     2     3      3       10   7   8  10  \n",
              "3    ...      3        2      2     1     1      5        2  15  14  15  \n",
              "4    ...      4        3      2     1     2      5        4   6  10  10  \n",
              "..   ...    ...      ...    ...   ...   ...    ...      ...  ..  ..  ..  \n",
              "390  ...      5        5      4     4     5      4       11   9   9   9  \n",
              "391  ...      2        4      5     3     4      2        3  14  16  16  \n",
              "392  ...      5        5      3     3     3      3        3  10   8   7  \n",
              "393  ...      4        4      1     3     4      5        0  11  12  10  \n",
              "394  ...      3        2      3     3     3      5        5   8   9   9  \n",
              "\n",
              "[395 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d491b147-64f4-4c25-acf7-c861dc3e81a4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>address</th>\n",
              "      <th>famsize</th>\n",
              "      <th>Pstatus</th>\n",
              "      <th>Medu</th>\n",
              "      <th>Fedu</th>\n",
              "      <th>Mjob</th>\n",
              "      <th>Fjob</th>\n",
              "      <th>...</th>\n",
              "      <th>famrel</th>\n",
              "      <th>freetime</th>\n",
              "      <th>goout</th>\n",
              "      <th>Dalc</th>\n",
              "      <th>Walc</th>\n",
              "      <th>health</th>\n",
              "      <th>absences</th>\n",
              "      <th>G1</th>\n",
              "      <th>G2</th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>18</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>A</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>at_home</td>\n",
              "      <td>teacher</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>at_home</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>15</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>health</td>\n",
              "      <td>services</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GP</td>\n",
              "      <td>F</td>\n",
              "      <td>16</td>\n",
              "      <td>U</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>20</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>services</td>\n",
              "      <td>services</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>17</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>services</td>\n",
              "      <td>services</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>21</td>\n",
              "      <td>R</td>\n",
              "      <td>GT3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>18</td>\n",
              "      <td>R</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>services</td>\n",
              "      <td>other</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>MS</td>\n",
              "      <td>M</td>\n",
              "      <td>19</td>\n",
              "      <td>U</td>\n",
              "      <td>LE3</td>\n",
              "      <td>T</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>other</td>\n",
              "      <td>at_home</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>395 rows × 33 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d491b147-64f4-4c25-acf7-c861dc3e81a4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d491b147-64f4-4c25-acf7-c861dc3e81a4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d491b147-64f4-4c25-acf7-c861dc3e81a4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-81d1c885-9e15-4a8c-a54e-96db8dab0db3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-81d1c885-9e15-4a8c-a54e-96db8dab0db3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-81d1c885-9e15-4a8c-a54e-96db8dab0db3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f0142dcf-1d90-42c9-b67c-dec6801e4e99\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f0142dcf-1d90-42c9-b67c-dec6801e4e99 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPUML7i0t6Rj",
        "outputId": "67856f50-4d38-4284-8483-c5790888a842"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 395 entries, 0 to 394\n",
            "Data columns (total 33 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   school      395 non-null    object\n",
            " 1   sex         395 non-null    object\n",
            " 2   age         395 non-null    int64 \n",
            " 3   address     395 non-null    object\n",
            " 4   famsize     395 non-null    object\n",
            " 5   Pstatus     395 non-null    object\n",
            " 6   Medu        395 non-null    int64 \n",
            " 7   Fedu        395 non-null    int64 \n",
            " 8   Mjob        395 non-null    object\n",
            " 9   Fjob        395 non-null    object\n",
            " 10  reason      395 non-null    object\n",
            " 11  guardian    395 non-null    object\n",
            " 12  traveltime  395 non-null    int64 \n",
            " 13  studytime   395 non-null    int64 \n",
            " 14  failures    395 non-null    int64 \n",
            " 15  schoolsup   395 non-null    object\n",
            " 16  famsup      395 non-null    object\n",
            " 17  paid        395 non-null    object\n",
            " 18  activities  395 non-null    object\n",
            " 19  nursery     395 non-null    object\n",
            " 20  higher      395 non-null    object\n",
            " 21  internet    395 non-null    object\n",
            " 22  romantic    395 non-null    object\n",
            " 23  famrel      395 non-null    int64 \n",
            " 24  freetime    395 non-null    int64 \n",
            " 25  goout       395 non-null    int64 \n",
            " 26  Dalc        395 non-null    int64 \n",
            " 27  Walc        395 non-null    int64 \n",
            " 28  health      395 non-null    int64 \n",
            " 29  absences    395 non-null    int64 \n",
            " 30  G1          395 non-null    int64 \n",
            " 31  G2          395 non-null    int64 \n",
            " 32  G3          395 non-null    int64 \n",
            "dtypes: int64(16), object(17)\n",
            "memory usage: 102.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 데이터 분리\n",
        "### 문제는 반드시 2차원이라 large X\n",
        "1. 문제(X)와 정답(y)\n",
        "2. train, test (7:3)"
      ],
      "metadata": {
        "id": "AiJgyNeDt6PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 문제, 정답 분리\n",
        "X = data['studytime']\n",
        "y = data['G3']"
      ],
      "metadata": {
        "id": "v2bOw8Hjt56M"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, test 분리\n",
        "# 분리도구 불러오기\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=92)"
      ],
      "metadata": {
        "id": "Frk1IrvSy3fe"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 크기확인\n",
        "print('훈련용 문제: ',X_train.shape)\n",
        "print('훈련용 답: ',y_train.shape)\n",
        "print('테스트용 문제: ',X_test.shape)\n",
        "print('테스트용 답: ',y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdcDkqOHy3dZ",
        "outputId": "e54c1908-fd4e-4adc-d843-9dae6ba6cb48"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 문제:  (276,)\n",
            "훈련용 답:  (276,)\n",
            "테스트용 문제:  (119,)\n",
            "테스트용 답:  (119,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X.values.reshape(행,열)\n",
        "X.values.reshape(-1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bnbR3GIq2Wt6",
        "outputId": "0379699f-a750-4f48-8948-1ca6d652299a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1],\n",
              "       [3],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [4],\n",
              "       [2],\n",
              "       [4],\n",
              "       [4],\n",
              "       [4],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [4],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [4],\n",
              "       [3],\n",
              "       [4],\n",
              "       [3],\n",
              "       [1],\n",
              "       [3],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [4],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [4],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [4],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [3],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [3],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [4],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [3],\n",
              "       [4],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [3],\n",
              "       [4],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [4],\n",
              "       [3],\n",
              "       [3],\n",
              "       [2],\n",
              "       [4],\n",
              "       [2],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [3],\n",
              "       [1],\n",
              "       [1],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [3],\n",
              "       [3],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [3],\n",
              "       [1],\n",
              "       [3],\n",
              "       [2],\n",
              "       [2],\n",
              "       [2],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 머신러닝 모델링 -> 회귀 (수학성적점수)\n",
        "# 0. 모델 불러오기\n",
        "from sklearn.linear_model import LinearRegression # 선형회귀모델\n",
        "# 1. 모델 객체생성\n",
        "linear_model = LinearRegression()\n",
        "# 2. 모델 학습 fit(학습용문제, 학습용정답)\n",
        "# 주의!! 문제데이터는 늘 2차원!!\n",
        "linear_model.fit(X_train.values.reshape(-1,1), y_train)\n",
        "# 3. 모델 예측 predict(테스트용 문제) -> 2차원\n",
        "\n",
        "pre = linear_model.predict(X_test.values.reshape(-1,1))\n",
        "# 4. 모델 평가 score -> r2 score\n",
        "# mse 출력 해보기!!!\n",
        "# mean_squared_error(실제값, 예측값), mse\n",
        "from sklearn.metrics import mean_squared_error\n",
        "mean_squared_error(y_test, pre)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F7M9pxmy3bI",
        "outputId": "501d8cf7-6aee-4a63-88bf-7b38054db7dc"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24.819783179817342"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 목표\n",
        "- tensorflow의 keras 활용해서 인공신경망을 구성하는 방법을 살펴보자!\n",
        "- 학생 수학 성적을 예측하는 회귀 모델을 완성시켜보자!\n"
      ],
      "metadata": {
        "id": "nqTML4Dsy3Yg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 신경망 모델 만들기\n",
        "- 1. 모델 구조 설계 ( 틀 불러와서 사용)\n",
        "- 2. 학습/평가 방법 설정(컴파일)\n",
        "- 3. 모델 학습 및 학습 현황 시각화\n",
        "- 4. 모델 예측 및 평가"
      ],
      "metadata": {
        "id": "0Ekc86-4y3WM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 환경세팅\n",
        "from tensorflow.keras import Sequential\n",
        "# Sequential : 인공신경망의 뼈대를 구축하기 위한 함수(기능, 도구)\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "# Dense : 신경망층을 구성하는 함수(기능)\n",
        "# Activation : 활성화 함수(각층의 정보를 전달하는 중간 역할)"
      ],
      "metadata": {
        "id": "mo_yiqLuJqU2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 컬럼명 확인하기\n",
        "# 전체정보\n",
        "data.info()\n",
        "# studytime int(숫자) - 컬럼(특성) 1개만 활용해서 딥러닝 학습시키기!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6f3-_M-NLRH",
        "outputId": "c7925b22-8fd3-4391-9ea4-00a41e05a7f0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 395 entries, 0 to 394\n",
            "Data columns (total 33 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   school      395 non-null    object\n",
            " 1   sex         395 non-null    object\n",
            " 2   age         395 non-null    int64 \n",
            " 3   address     395 non-null    object\n",
            " 4   famsize     395 non-null    object\n",
            " 5   Pstatus     395 non-null    object\n",
            " 6   Medu        395 non-null    int64 \n",
            " 7   Fedu        395 non-null    int64 \n",
            " 8   Mjob        395 non-null    object\n",
            " 9   Fjob        395 non-null    object\n",
            " 10  reason      395 non-null    object\n",
            " 11  guardian    395 non-null    object\n",
            " 12  traveltime  395 non-null    int64 \n",
            " 13  studytime   395 non-null    int64 \n",
            " 14  failures    395 non-null    int64 \n",
            " 15  schoolsup   395 non-null    object\n",
            " 16  famsup      395 non-null    object\n",
            " 17  paid        395 non-null    object\n",
            " 18  activities  395 non-null    object\n",
            " 19  nursery     395 non-null    object\n",
            " 20  higher      395 non-null    object\n",
            " 21  internet    395 non-null    object\n",
            " 22  romantic    395 non-null    object\n",
            " 23  famrel      395 non-null    int64 \n",
            " 24  freetime    395 non-null    int64 \n",
            " 25  goout       395 non-null    int64 \n",
            " 26  Dalc        395 non-null    int64 \n",
            " 27  Walc        395 non-null    int64 \n",
            " 28  health      395 non-null    int64 \n",
            " 29  absences    395 non-null    int64 \n",
            " 30  G1          395 non-null    int64 \n",
            " 31  G2          395 non-null    int64 \n",
            " 32  G3          395 non-null    int64 \n",
            "dtypes: int64(16), object(17)\n",
            "memory usage: 102.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 모델 설계\n",
        "# 뼈대 설계\n",
        "model = Sequential()\n",
        "\n",
        "# 층 내용 설계\n",
        "# 입력층 + 중간층(1개)\n",
        "# units (뉴런)개수 설정 : 정답이 x → 사람이 설정하는 파라미터(하이퍼 파라미터)\n",
        "# units 4개 설정\n",
        "# input_dim : 입력 특성의 크기(개수, 차원) → 사용 특성(열)의 개수\n",
        "# 데이터의 크기는 입력층에서만 input_dim 활용해서 설정\n",
        "model.add(Dense(units=4, input_dim=1))\n",
        "model.add(Activation('sigmoid'))\n",
        "# 각 유닛(뉴런)에는 활성화함수가 연결됨 -> 데이터 전달하는 중간다리 역할, 사람은 추상적인 사고\n",
        "\n",
        "# 출력층\n",
        "# 회귀 출력층 units=1, Activation='linear' / y=wx+b 이건 공식임!!!!!(회귀일때만 생략 가능)\n",
        "# 뉴런 y=wx+b\n",
        "model.add(Dense(units=1))\n",
        "#model.add(Activation('linear')) 회귀니까 생략 가능\n",
        "\n",
        "# 모델 정보 요약\n",
        "model.summary()\n",
        "\n",
        "# Param : 해당 층(중간층1)에 w,b의 총 개수 => 모델의 복잡도 파악이 가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "y4eN7Bdmy3Tm",
        "outputId": "b07729b8-8ec8-4c36-f6da-982e1ae6e970"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m5\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13\u001b[0m (52.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> (52.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13\u001b[0m (52.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> (52.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 모델 학습/평가 방법 설정(compile, 컴파일)\n",
        "# 모델.compile(오차계산, 최적화함수, 평가지표)\n",
        "# loss(손실함수)\n",
        "# - 회귀 : mse\n",
        "# optimizer(최적화함수) : 다양한 종류가 존재\n",
        "# 평가지표\n",
        "# - 회귀 : mse, rmse, mae, r2_score\n",
        "# - 분류 : accuracy, recall(재현율), precision, f1-score\n",
        "# 'mse' > mse() 공식이 실행되는 것\n",
        "model.compile(loss='mse', # 평균제곱오차\n",
        "              optimizer='sgd', # 경사하강법:sgd\n",
        "              )"
      ],
      "metadata": {
        "id": "kikxBz1_y3RR"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMZMrm_sW9O2",
        "outputId": "370ade98-b4c1-4934-b485-738d83ec662e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
              "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
              "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
              "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
              "       'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# studytime 특성 1개 잘라서\n",
        "# train, test 분리\n",
        "X = data['studytime']\n",
        "X.ndim # number of dimension 차원의 수 >> 1차원\n",
        "X.shape # 1차원 (숫자,)\n",
        "y = data['G3']\n",
        "y.shape\n",
        "\n",
        "# 훈련셋, 테스트셋 분리\n",
        "# 7:3\n",
        "# random_state = 4\n",
        "# test_size = 30 30개의 행만 test, 365개 train 행으로 분리\n",
        "# 비율의 개념 : 실수형태로 입력\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=4)\n",
        "print('train set:', X_train.shape, y_train.shape)\n",
        "print('test set:', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghu30NoDWvx9",
        "outputId": "82d2bcf0-9b44-4adc-efb8-feb0502dc3ec"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: (276,) (276,)\n",
            "test set: (119,) (119,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 모델 학습 및 시각화\n",
        "# 모델명.fit(훈련문제, 훈련답,반복횟수)\n",
        "# 반복횟수 : epochs(에포크)\n",
        "# 300번 반복\n",
        "h = model.fit(X_train, y_train, epochs=300)\n",
        "# 새롭게 학습을 진행하거나, 코드 에러 문제를 해결하고 학습을 재실행할 경우\n",
        "# Sequential 뼈대구축하는 코드부터 재실행해야함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "W3MBHqFsy3PD",
        "outputId": "a1fa9555-c4ef-47a7-a41a-0133defb8a41"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.9246  \n",
            "Epoch 2/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 51.1336 \n",
            "Epoch 3/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.0608 \n",
            "Epoch 4/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.1794 \n",
            "Epoch 5/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.8830 \n",
            "Epoch 6/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8176 \n",
            "Epoch 7/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3259 \n",
            "Epoch 8/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3813 \n",
            "Epoch 9/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.7750 \n",
            "Epoch 10/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.9255 \n",
            "Epoch 11/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.8681 \n",
            "Epoch 12/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8372 \n",
            "Epoch 13/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.4431 \n",
            "Epoch 14/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0597 \n",
            "Epoch 15/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.6737 \n",
            "Epoch 16/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2653 \n",
            "Epoch 17/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3815 \n",
            "Epoch 18/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.5736 \n",
            "Epoch 19/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7769 \n",
            "Epoch 20/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5235 \n",
            "Epoch 21/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6261 \n",
            "Epoch 22/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.8564 \n",
            "Epoch 23/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5524 \n",
            "Epoch 24/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7687 \n",
            "Epoch 25/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4576 \n",
            "Epoch 26/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9570 \n",
            "Epoch 27/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2180 \n",
            "Epoch 28/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2227 \n",
            "Epoch 29/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.7637 \n",
            "Epoch 30/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7459 \n",
            "Epoch 31/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2387 \n",
            "Epoch 32/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5652 \n",
            "Epoch 33/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8421 \n",
            "Epoch 34/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.3786 \n",
            "Epoch 35/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7065 \n",
            "Epoch 36/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.0974\n",
            "Epoch 37/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9934 \n",
            "Epoch 38/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6162 \n",
            "Epoch 39/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.9263 \n",
            "Epoch 40/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7827 \n",
            "Epoch 41/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3277 \n",
            "Epoch 42/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.5949 \n",
            "Epoch 43/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7220 \n",
            "Epoch 44/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.5501 \n",
            "Epoch 45/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9108 \n",
            "Epoch 46/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.1989 \n",
            "Epoch 47/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2123 \n",
            "Epoch 48/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3373 \n",
            "Epoch 49/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8206 \n",
            "Epoch 50/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.4854 \n",
            "Epoch 51/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0073 \n",
            "Epoch 52/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.1759 \n",
            "Epoch 53/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1188 \n",
            "Epoch 54/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7346 \n",
            "Epoch 55/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9500 \n",
            "Epoch 56/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1924 \n",
            "Epoch 57/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0643 \n",
            "Epoch 58/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.9016 \n",
            "Epoch 59/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0932 \n",
            "Epoch 60/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1233 \n",
            "Epoch 61/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2662 \n",
            "Epoch 62/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.8510 \n",
            "Epoch 63/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2137 \n",
            "Epoch 64/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2250 \n",
            "Epoch 65/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3887 \n",
            "Epoch 66/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5115 \n",
            "Epoch 67/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.2732 \n",
            "Epoch 68/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4734 \n",
            "Epoch 69/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7883 \n",
            "Epoch 70/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.2773 \n",
            "Epoch 71/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8435 \n",
            "Epoch 72/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2669 \n",
            "Epoch 73/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3540 \n",
            "Epoch 74/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0282 \n",
            "Epoch 75/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1376 \n",
            "Epoch 76/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.2915 \n",
            "Epoch 77/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2790 \n",
            "Epoch 78/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.4379 \n",
            "Epoch 79/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.2125 \n",
            "Epoch 80/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.5907 \n",
            "Epoch 81/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.0587  \n",
            "Epoch 82/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.1222 \n",
            "Epoch 83/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7578  \n",
            "Epoch 84/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.0622 \n",
            "Epoch 85/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.1877 \n",
            "Epoch 86/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2422 \n",
            "Epoch 87/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.8359  \n",
            "Epoch 88/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.9362  \n",
            "Epoch 89/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.1219 \n",
            "Epoch 90/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1105 \n",
            "Epoch 91/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.6303 \n",
            "Epoch 92/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.7813 \n",
            "Epoch 93/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.1843  \n",
            "Epoch 94/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.1602 \n",
            "Epoch 95/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9765 \n",
            "Epoch 96/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.9265 \n",
            "Epoch 97/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.4553  \n",
            "Epoch 98/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.6433 \n",
            "Epoch 99/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.6528 \n",
            "Epoch 100/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.8476 \n",
            "Epoch 101/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.4520  \n",
            "Epoch 102/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.6792  \n",
            "Epoch 103/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8925 \n",
            "Epoch 104/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2224 \n",
            "Epoch 105/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.0757 \n",
            "Epoch 106/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.0120  \n",
            "Epoch 107/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.8543 \n",
            "Epoch 108/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.7590 \n",
            "Epoch 109/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.3932  \n",
            "Epoch 110/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.1605  \n",
            "Epoch 111/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.0214  \n",
            "Epoch 112/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.5421 \n",
            "Epoch 113/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.3146 \n",
            "Epoch 114/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.7505  \n",
            "Epoch 115/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.7078  \n",
            "Epoch 116/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.4296 \n",
            "Epoch 117/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.7237\n",
            "Epoch 118/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.4840  \n",
            "Epoch 119/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.0027 \n",
            "Epoch 120/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.7737\n",
            "Epoch 121/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8212  \n",
            "Epoch 122/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.6663 \n",
            "Epoch 123/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9792 \n",
            "Epoch 124/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2610 \n",
            "Epoch 125/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.6909 \n",
            "Epoch 126/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.1276 \n",
            "Epoch 127/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6065 \n",
            "Epoch 128/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9610 \n",
            "Epoch 129/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2800 \n",
            "Epoch 130/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.8560 \n",
            "Epoch 131/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5824 \n",
            "Epoch 132/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3162 \n",
            "Epoch 133/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.9818 \n",
            "Epoch 134/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.9035 \n",
            "Epoch 135/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.7975  \n",
            "Epoch 136/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.4954 \n",
            "Epoch 137/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1092 \n",
            "Epoch 138/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.4811 \n",
            "Epoch 139/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.8218 \n",
            "Epoch 140/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1078 \n",
            "Epoch 141/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.4186 \n",
            "Epoch 142/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7383 \n",
            "Epoch 143/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.6086 \n",
            "Epoch 144/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5132 \n",
            "Epoch 145/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.5960 \n",
            "Epoch 146/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.7583 \n",
            "Epoch 147/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7131 \n",
            "Epoch 148/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.5217 \n",
            "Epoch 149/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7255\n",
            "Epoch 150/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.3260 \n",
            "Epoch 151/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6816  \n",
            "Epoch 152/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3074 \n",
            "Epoch 153/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2692 \n",
            "Epoch 154/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3792 \n",
            "Epoch 155/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2886 \n",
            "Epoch 156/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5152 \n",
            "Epoch 157/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7068 \n",
            "Epoch 158/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.4017 \n",
            "Epoch 159/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0236 \n",
            "Epoch 160/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.7101 \n",
            "Epoch 161/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.4063 \n",
            "Epoch 162/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.6825 \n",
            "Epoch 163/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.3943 \n",
            "Epoch 164/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.5494 \n",
            "Epoch 165/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.5333 \n",
            "Epoch 166/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.7888 \n",
            "Epoch 167/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.4199 \n",
            "Epoch 168/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.5409  \n",
            "Epoch 169/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8600 \n",
            "Epoch 170/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4758 \n",
            "Epoch 171/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.8161 \n",
            "Epoch 172/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6901  \n",
            "Epoch 173/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0144 \n",
            "Epoch 174/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4574 \n",
            "Epoch 175/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3152 \n",
            "Epoch 176/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8944 \n",
            "Epoch 177/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.6495 \n",
            "Epoch 178/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.9747 \n",
            "Epoch 179/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7531  \n",
            "Epoch 180/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.4749 \n",
            "Epoch 181/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.5501 \n",
            "Epoch 182/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.2009 \n",
            "Epoch 183/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1028\n",
            "Epoch 184/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2961 \n",
            "Epoch 185/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9169 \n",
            "Epoch 186/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.8444\n",
            "Epoch 187/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9462 \n",
            "Epoch 188/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.3250 \n",
            "Epoch 189/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.0536 \n",
            "Epoch 190/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1797 \n",
            "Epoch 191/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.2925 \n",
            "Epoch 192/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.0532 \n",
            "Epoch 193/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.9640 \n",
            "Epoch 194/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.3907 \n",
            "Epoch 195/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.2408  \n",
            "Epoch 196/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9962 \n",
            "Epoch 197/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3500 \n",
            "Epoch 198/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.8643 \n",
            "Epoch 199/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2600 \n",
            "Epoch 200/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0186 \n",
            "Epoch 201/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9594 \n",
            "Epoch 202/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.5300 \n",
            "Epoch 203/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.4816 \n",
            "Epoch 204/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3596 \n",
            "Epoch 205/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3345 \n",
            "Epoch 206/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.3265 \n",
            "Epoch 207/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.7370 \n",
            "Epoch 208/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.0981 \n",
            "Epoch 209/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9244  \n",
            "Epoch 210/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.5166  \n",
            "Epoch 211/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.9722 \n",
            "Epoch 212/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7272 \n",
            "Epoch 213/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.3323 \n",
            "Epoch 214/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.5848 \n",
            "Epoch 215/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.9457 \n",
            "Epoch 216/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6887 \n",
            "Epoch 217/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6300 \n",
            "Epoch 218/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.6857 \n",
            "Epoch 219/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.2590 \n",
            "Epoch 220/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8945 \n",
            "Epoch 221/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.1662 \n",
            "Epoch 222/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.2867 \n",
            "Epoch 223/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1769  \n",
            "Epoch 224/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1097 \n",
            "Epoch 225/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.7455 \n",
            "Epoch 226/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.2324 \n",
            "Epoch 227/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.7609 \n",
            "Epoch 228/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8647 \n",
            "Epoch 229/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.7721 \n",
            "Epoch 230/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7368 \n",
            "Epoch 231/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.6395 \n",
            "Epoch 232/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.6947 \n",
            "Epoch 233/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.1980 \n",
            "Epoch 234/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.3377 \n",
            "Epoch 235/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.5073 \n",
            "Epoch 236/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1817 \n",
            "Epoch 237/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0199 \n",
            "Epoch 238/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.0536 \n",
            "Epoch 239/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.4220  \n",
            "Epoch 240/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5742 \n",
            "Epoch 241/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3240 \n",
            "Epoch 242/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.2458 \n",
            "Epoch 243/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.7890\n",
            "Epoch 244/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.0597 \n",
            "Epoch 245/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.2848 \n",
            "Epoch 246/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9680 \n",
            "Epoch 247/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6778 \n",
            "Epoch 248/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6266 \n",
            "Epoch 249/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.0289 \n",
            "Epoch 250/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4503 \n",
            "Epoch 251/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0584 \n",
            "Epoch 252/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.9192 \n",
            "Epoch 253/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.9416 \n",
            "Epoch 254/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.7876 \n",
            "Epoch 255/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.2090  \n",
            "Epoch 256/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.9606\n",
            "Epoch 257/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.6519 \n",
            "Epoch 258/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.8578 \n",
            "Epoch 259/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.1106 \n",
            "Epoch 260/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.2797 \n",
            "Epoch 261/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.0549 \n",
            "Epoch 262/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.2916 \n",
            "Epoch 263/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3680 \n",
            "Epoch 264/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.3327 \n",
            "Epoch 265/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7363 \n",
            "Epoch 266/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1285 \n",
            "Epoch 267/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.2094 \n",
            "Epoch 268/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.9717 \n",
            "Epoch 269/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.7873 \n",
            "Epoch 270/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.2890 \n",
            "Epoch 271/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.5887  \n",
            "Epoch 272/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 20.5098  \n",
            "Epoch 273/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.4285  \n",
            "Epoch 274/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.8476 \n",
            "Epoch 275/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8920 \n",
            "Epoch 276/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.6218 \n",
            "Epoch 277/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.1134  \n",
            "Epoch 278/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.1267  \n",
            "Epoch 279/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.7199 \n",
            "Epoch 280/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.6537 \n",
            "Epoch 281/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.9979  \n",
            "Epoch 282/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.9908 \n",
            "Epoch 283/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.4500  \n",
            "Epoch 284/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.5624  \n",
            "Epoch 285/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.0863  \n",
            "Epoch 286/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.7806 \n",
            "Epoch 287/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.6506  \n",
            "Epoch 288/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.2194 \n",
            "Epoch 289/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.4793 \n",
            "Epoch 290/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.5302 \n",
            "Epoch 291/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.2493  \n",
            "Epoch 292/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.5740 \n",
            "Epoch 293/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 20.4482  \n",
            "Epoch 294/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 17.9600 \n",
            "Epoch 295/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.8279 \n",
            "Epoch 296/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.8420  \n",
            "Epoch 297/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.6602  \n",
            "Epoch 298/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.9616  \n",
            "Epoch 299/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 19.3846  \n",
            "Epoch 300/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 19.3737  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화 - 수치의 추이를 확인할 수 있는 그래프 (선그래프)\n",
        "h.history.keys() # dict\n",
        "h_loss = h.history['loss']\n",
        "h_loss\n",
        "\n",
        "# x축 반복횟수, y축 loss\n",
        "plt.plot(range(1,301), h_loss)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "3B0Sc0jpy3Mt",
        "outputId": "85fd6ea8-1aaa-4043-8bc9-4fc11ac154b4"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델마다 오차의 시작점이 다름 >> y=wx+b(선형함수) w,b의 세팅 초반에 랜덤하게 셋팅\n",
        "# 여러번 반복하면서 오차가 최소가 되게하는 w,b를 찾는 것이 딥러닝 신경망 모델의 목적\n",
        "# 300번 반복을 진행하지만, 10~20번째 사이에서 오차의 개선이 빠르게 진행됨을 알 수 있음(장점)\n",
        "# 오차가 20 정도에서 수렴 > 1. 데이터를 더 좋은 특성을 많이 연결 2. 모델 설계 부분 조정, 하이퍼 파라미터 변경\n"
      ],
      "metadata": {
        "id": "tdkvWhRby3KY"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기술통계\n",
        "y.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "tHw1vuaTejxQ",
        "outputId": "b8f5d67a-b7e8-4a08-a748-f524aa2b04d9"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    395.000000\n",
              "mean      10.415190\n",
              "std        4.581443\n",
              "min        0.000000\n",
              "25%        8.000000\n",
              "50%       11.000000\n",
              "75%       14.000000\n",
              "max       20.000000\n",
              "Name: G3, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>395.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.415190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.581443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 모델 예측\n",
        "# 모델.predict(문제)\n",
        "pre = model.predict(X_test)\n",
        "pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MqDiAsHZy3IS",
        "outputId": "69fc5933-6824-4925-8389-9d88d03c07fd"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79504108cdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79504108cdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10.73969 ],\n",
              "       [11.620368],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.005202],\n",
              "       [11.620368],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [11.620368],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [11.620368],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [11.620368],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [11.620368],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [11.620368],\n",
              "       [10.005202],\n",
              "       [11.264196],\n",
              "       [11.264196],\n",
              "       [11.620368],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [11.264196],\n",
              "       [11.264196],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.005202],\n",
              "       [11.264196],\n",
              "       [11.264196],\n",
              "       [11.620368],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ],\n",
              "       [10.73969 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "# 모델 기본적인 평가 기능(도구) : 회귀 mse\n",
        "# 모델.test score evaluate(o)\n",
        "# 머신러닝 sklearn 모델 score 함수비교\n",
        "# model.score(테스트문제, 테스트답)\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAmDhCpky3GC",
        "outputId": "594245ac-ea5e-45e8-b69c-6c293cf11348"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.8811  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.33289337158203"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2번째 신경망 모델 자유롭게 쌓아보기\n",
        "- 특성을 총 2개를 활용해서 모델 학습시켜보기\n",
        "- studytime, freetime 자유시간 컬럼을 연결해서 수학성적 예측\n",
        "- 인공신경망 모델을 통해 학습시켜보자!\n",
        "- 모델 설계는 자유롭게\n",
        "  - units 개수를 알아서 설정해보기\n",
        "  - 중간층 개수를 늘려보기\n",
        "  "
      ],
      "metadata": {
        "id": "wSO7iWvFy3EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 모델 설계 model2\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(units=4, input_dim=2))\n",
        "model2.add(Activation('sigmoid'))\n",
        "model.add(Dense(units=1))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "collapsed": true,
        "id": "lxlhSqvny3CD",
        "outputId": "70f9c71d-bd24-415e-a1df-851fc9102df7"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m8\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m5\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │               \u001b[38;5;34m2\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17\u001b[0m (72.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (72.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15\u001b[0m (60.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> (60.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 모델 학습/평가 방법\n",
        "model2.compile(loss='mse', optimizer='sgd')\n"
      ],
      "metadata": {
        "id": "gYWbnM4Ly3AI"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 학습, h 변수 담아서 시각화 연결\n",
        "X=data[['studytime','freetime']]\n",
        "X.ndim\n",
        "X.shape\n",
        "y=data['G3']\n",
        "y.shape\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=4)\n",
        "print('train set:', X_train.shape, y_train.shape)\n",
        "print('test_set:', X_test.shape, y_test.shape)\n",
        "h2=model2.fit(X_train, y_train, epochs=300)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ7WB0Uty295",
        "outputId": "b0625395-2c26-4cfa-d68b-90f9386da8bf"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: (276, 2) (276,)\n",
            "test_set: (119, 2) (119,)\n",
            "Epoch 1/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.5283  \n",
            "Epoch 2/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 121.9345 \n",
            "Epoch 3/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.7031 \n",
            "Epoch 4/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.8951 \n",
            "Epoch 5/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112.3968  \n",
            "Epoch 6/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.8075 \n",
            "Epoch 7/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.5091  \n",
            "Epoch 8/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.0067  \n",
            "Epoch 9/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.6687 \n",
            "Epoch 10/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109.5768\n",
            "Epoch 11/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.8005  \n",
            "Epoch 12/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.7522  \n",
            "Epoch 13/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.3605  \n",
            "Epoch 14/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.2427  \n",
            "Epoch 15/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 119.3965  \n",
            "Epoch 16/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.7627 \n",
            "Epoch 17/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.5239 \n",
            "Epoch 18/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.3410  \n",
            "Epoch 19/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.4385 \n",
            "Epoch 20/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.3686 \n",
            "Epoch 21/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.0663 \n",
            "Epoch 22/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.0845\n",
            "Epoch 23/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.1451 \n",
            "Epoch 24/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.6266 \n",
            "Epoch 25/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 115.1856  \n",
            "Epoch 26/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.7339 \n",
            "Epoch 27/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.6961  \n",
            "Epoch 28/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.5952\n",
            "Epoch 29/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.6449 \n",
            "Epoch 30/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.9156  \n",
            "Epoch 31/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.6045 \n",
            "Epoch 32/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120.0802  \n",
            "Epoch 33/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.5875 \n",
            "Epoch 34/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 109.1727  \n",
            "Epoch 35/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120.9844 \n",
            "Epoch 36/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.9645 \n",
            "Epoch 37/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.7712 \n",
            "Epoch 38/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.5252 \n",
            "Epoch 39/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.8685 \n",
            "Epoch 40/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.3874  \n",
            "Epoch 41/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.8282 \n",
            "Epoch 42/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.0552 \n",
            "Epoch 43/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.9250\n",
            "Epoch 44/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.6286 \n",
            "Epoch 45/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.3562 \n",
            "Epoch 46/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.9312 \n",
            "Epoch 47/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.3292  \n",
            "Epoch 48/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.4210 \n",
            "Epoch 49/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.4609 \n",
            "Epoch 50/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.2204\n",
            "Epoch 51/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.4474 \n",
            "Epoch 52/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.8465 \n",
            "Epoch 53/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.6294 \n",
            "Epoch 54/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.9448 \n",
            "Epoch 55/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.1959\n",
            "Epoch 56/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.8237 \n",
            "Epoch 57/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 106.2183 \n",
            "Epoch 58/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.5091 \n",
            "Epoch 59/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.3730 \n",
            "Epoch 60/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.8463 \n",
            "Epoch 61/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.7550 \n",
            "Epoch 62/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.1591 \n",
            "Epoch 63/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.2020 \n",
            "Epoch 64/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 107.6925  \n",
            "Epoch 65/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.4448 \n",
            "Epoch 66/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.6511 \n",
            "Epoch 67/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.3605  \n",
            "Epoch 68/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.5629\n",
            "Epoch 69/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.8573 \n",
            "Epoch 70/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.8742 \n",
            "Epoch 71/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113.1014  \n",
            "Epoch 72/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120.3134  \n",
            "Epoch 73/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.6884 \n",
            "Epoch 74/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.5565 \n",
            "Epoch 75/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113.6015 \n",
            "Epoch 76/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.9638 \n",
            "Epoch 77/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.6180 \n",
            "Epoch 78/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114.7719  \n",
            "Epoch 79/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120.3318 \n",
            "Epoch 80/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.5946 \n",
            "Epoch 81/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.1189  \n",
            "Epoch 82/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 114.5571 \n",
            "Epoch 83/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 112.7388 \n",
            "Epoch 84/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.2043 \n",
            "Epoch 85/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 113.5487  \n",
            "Epoch 86/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 114.6306  \n",
            "Epoch 87/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.8354  \n",
            "Epoch 88/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 111.4261 \n",
            "Epoch 89/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113.0992  \n",
            "Epoch 90/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.4667  \n",
            "Epoch 91/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 108.4202 \n",
            "Epoch 92/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.1762  \n",
            "Epoch 93/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 108.6697 \n",
            "Epoch 94/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.2894  \n",
            "Epoch 95/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 115.5909  \n",
            "Epoch 96/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 120.8259  \n",
            "Epoch 97/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 111.8814\n",
            "Epoch 98/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.5192  \n",
            "Epoch 99/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.7065  \n",
            "Epoch 100/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.0390 \n",
            "Epoch 101/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.3758  \n",
            "Epoch 102/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.4720 \n",
            "Epoch 103/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.5082\n",
            "Epoch 104/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.2783 \n",
            "Epoch 105/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.3427 \n",
            "Epoch 106/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.4333 \n",
            "Epoch 107/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.8080 \n",
            "Epoch 108/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.7480 \n",
            "Epoch 109/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.3883 \n",
            "Epoch 110/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.7268 \n",
            "Epoch 111/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.6457 \n",
            "Epoch 112/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.6881 \n",
            "Epoch 113/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.7229 \n",
            "Epoch 114/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.6537 \n",
            "Epoch 115/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.1035 \n",
            "Epoch 116/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 119.2411 \n",
            "Epoch 117/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.3825 \n",
            "Epoch 118/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.9133 \n",
            "Epoch 119/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.7021 \n",
            "Epoch 120/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 104.2677\n",
            "Epoch 121/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.9879 \n",
            "Epoch 122/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120.1601 \n",
            "Epoch 123/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.8960  \n",
            "Epoch 124/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.8658 \n",
            "Epoch 125/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.3285 \n",
            "Epoch 126/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.8663  \n",
            "Epoch 127/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.3233  \n",
            "Epoch 128/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.7034  \n",
            "Epoch 129/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.7789 \n",
            "Epoch 130/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.5439 \n",
            "Epoch 131/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.3653  \n",
            "Epoch 132/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.1946 \n",
            "Epoch 133/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.6434  \n",
            "Epoch 134/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.9780  \n",
            "Epoch 135/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 111.7397  \n",
            "Epoch 136/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.7243  \n",
            "Epoch 137/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.3089  \n",
            "Epoch 138/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.0049  \n",
            "Epoch 139/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.7142 \n",
            "Epoch 140/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 115.1157  \n",
            "Epoch 141/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.2068  \n",
            "Epoch 142/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.4458 \n",
            "Epoch 143/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.2801 \n",
            "Epoch 144/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113.1762  \n",
            "Epoch 145/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.2232 \n",
            "Epoch 146/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.5732  \n",
            "Epoch 147/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 109.8198 \n",
            "Epoch 148/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117.4127  \n",
            "Epoch 149/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117.2285  \n",
            "Epoch 150/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.3122  \n",
            "Epoch 151/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.4654  \n",
            "Epoch 152/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 120.0423  \n",
            "Epoch 153/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.5974 \n",
            "Epoch 154/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.0186  \n",
            "Epoch 155/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.4474  \n",
            "Epoch 156/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 117.3547 \n",
            "Epoch 157/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.2341 \n",
            "Epoch 158/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.6496 \n",
            "Epoch 159/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.9240  \n",
            "Epoch 160/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.9080 \n",
            "Epoch 161/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.3653 \n",
            "Epoch 162/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 120.9534  \n",
            "Epoch 163/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.4659 \n",
            "Epoch 164/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.5726 \n",
            "Epoch 165/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.7442 \n",
            "Epoch 166/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.5501 \n",
            "Epoch 167/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.4720 \n",
            "Epoch 168/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.3711 \n",
            "Epoch 169/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.5625 \n",
            "Epoch 170/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.0439 \n",
            "Epoch 171/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.2482 \n",
            "Epoch 172/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.1723 \n",
            "Epoch 173/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.7003 \n",
            "Epoch 174/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.1610 \n",
            "Epoch 175/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.9307 \n",
            "Epoch 176/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.6816 \n",
            "Epoch 177/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.1540\n",
            "Epoch 178/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.8199  \n",
            "Epoch 179/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.1056\n",
            "Epoch 180/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.4268 \n",
            "Epoch 181/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.0185 \n",
            "Epoch 182/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.0841 \n",
            "Epoch 183/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.5323 \n",
            "Epoch 184/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.4311 \n",
            "Epoch 185/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.0421 \n",
            "Epoch 186/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.8902 \n",
            "Epoch 187/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 113.3898 \n",
            "Epoch 188/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.4863 \n",
            "Epoch 189/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.8357\n",
            "Epoch 190/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.3963 \n",
            "Epoch 191/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 110.5371 \n",
            "Epoch 192/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.5043  \n",
            "Epoch 193/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.1312 \n",
            "Epoch 194/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.7010 \n",
            "Epoch 195/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 119.9857 \n",
            "Epoch 196/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.8685 \n",
            "Epoch 197/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.8438 \n",
            "Epoch 198/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.3092 \n",
            "Epoch 199/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.5530 \n",
            "Epoch 200/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.0133 \n",
            "Epoch 201/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.4425 \n",
            "Epoch 202/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.2644  \n",
            "Epoch 203/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 108.5335 \n",
            "Epoch 204/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.1875 \n",
            "Epoch 205/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.5376 \n",
            "Epoch 206/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.9464 \n",
            "Epoch 207/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.6457 \n",
            "Epoch 208/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.0374 \n",
            "Epoch 209/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.2693 \n",
            "Epoch 210/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.0158 \n",
            "Epoch 211/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.6455\n",
            "Epoch 212/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.5007\n",
            "Epoch 213/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.4275 \n",
            "Epoch 214/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 113.1564 \n",
            "Epoch 215/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.2474 \n",
            "Epoch 216/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.4368  \n",
            "Epoch 217/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.4677 \n",
            "Epoch 218/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.9458 \n",
            "Epoch 219/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.8563  \n",
            "Epoch 220/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.5450 \n",
            "Epoch 221/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.0199 \n",
            "Epoch 222/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.7680 \n",
            "Epoch 223/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.3218 \n",
            "Epoch 224/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.6244 \n",
            "Epoch 225/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.5255 \n",
            "Epoch 226/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.3854 \n",
            "Epoch 227/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 110.3729 \n",
            "Epoch 228/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.2029 \n",
            "Epoch 229/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.9898 \n",
            "Epoch 230/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.6503 \n",
            "Epoch 231/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.1057 \n",
            "Epoch 232/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 108.2877  \n",
            "Epoch 233/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113.6938  \n",
            "Epoch 234/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 112.8773  \n",
            "Epoch 235/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 119.7674 \n",
            "Epoch 236/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.4014  \n",
            "Epoch 237/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 121.3010 \n",
            "Epoch 238/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 106.0260\n",
            "Epoch 239/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.0174 \n",
            "Epoch 240/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.4436 \n",
            "Epoch 241/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 117.7094 \n",
            "Epoch 242/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.8252 \n",
            "Epoch 243/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 109.6082\n",
            "Epoch 244/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.5484 \n",
            "Epoch 245/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.4195 \n",
            "Epoch 246/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.6977 \n",
            "Epoch 247/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 118.2806 \n",
            "Epoch 248/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.5366 \n",
            "Epoch 249/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.1674  \n",
            "Epoch 250/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.8485 \n",
            "Epoch 251/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.4243  \n",
            "Epoch 252/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.8285 \n",
            "Epoch 253/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.9384 \n",
            "Epoch 254/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.8869\n",
            "Epoch 255/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.5282\n",
            "Epoch 256/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.3575 \n",
            "Epoch 257/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.2072 \n",
            "Epoch 258/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.1644 \n",
            "Epoch 259/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.1745 \n",
            "Epoch 260/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.0463\n",
            "Epoch 261/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.4834 \n",
            "Epoch 262/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.3896  \n",
            "Epoch 263/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 108.3916 \n",
            "Epoch 264/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.8700 \n",
            "Epoch 265/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.1460 \n",
            "Epoch 266/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.5458 \n",
            "Epoch 267/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 115.1026 \n",
            "Epoch 268/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.0917 \n",
            "Epoch 269/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 116.5437 \n",
            "Epoch 270/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 110.5143 \n",
            "Epoch 271/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.9301 \n",
            "Epoch 272/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.9279 \n",
            "Epoch 273/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 118.7896 \n",
            "Epoch 274/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.7575 \n",
            "Epoch 275/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 117.5123 \n",
            "Epoch 276/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.7592  \n",
            "Epoch 277/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.7666 \n",
            "Epoch 278/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.7855 \n",
            "Epoch 279/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.4452  \n",
            "Epoch 280/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 109.6082  \n",
            "Epoch 281/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 112.2363 \n",
            "Epoch 282/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 112.8044 \n",
            "Epoch 283/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 114.9930 \n",
            "Epoch 284/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 116.1919  \n",
            "Epoch 285/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 116.4997  \n",
            "Epoch 286/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 110.5437 \n",
            "Epoch 287/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 111.8715 \n",
            "Epoch 288/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 115.3185  \n",
            "Epoch 289/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.5562 \n",
            "Epoch 290/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 111.5690  \n",
            "Epoch 291/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 114.8200 \n",
            "Epoch 292/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 116.9809 \n",
            "Epoch 293/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.6991 \n",
            "Epoch 294/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 115.1177\n",
            "Epoch 295/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 111.9684\n",
            "Epoch 296/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 121.3274\n",
            "Epoch 297/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 117.3026\n",
            "Epoch 298/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 112.3382  \n",
            "Epoch 299/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 117.3855\n",
            "Epoch 300/300\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 113.0218  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h2.history.keys()\n",
        "h2_loss = h2.history['loss']\n",
        "h2_loss\n",
        "\n",
        "plt.plot(range(1,301), h2_loss)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "dDMUyI1-m5D0",
        "outputId": "498b1b37-7929-473a-c59e-70cf04034172"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "hWlitwQtnVK6",
        "outputId": "ad8d9fe0-3102-44be-ec8c-37cb048a1f96"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    395.000000\n",
              "mean      10.415190\n",
              "std        4.581443\n",
              "min        0.000000\n",
              "25%        8.000000\n",
              "50%       11.000000\n",
              "75%       14.000000\n",
              "max       20.000000\n",
              "Name: G3, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>G3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>395.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>10.415190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>4.581443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>11.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 평가\n",
        "pre2 = model2.predict(X_test)\n",
        "pre2\n",
        "# model., model 2 성능 비교하면서 특성이 1개 더 늘었을 때의 개선 효과 확인\n",
        "# 파이썬 딥러닝 텐서플로 교재 50-61pg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4g4U2W_InVIc",
        "outputId": "fa686a58-29fa-4682-defb-7529924a156a"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99997073, 0.99996495, 0.9999719 , 0.9999512 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.989869  , 0.99030524, 0.9902013 , 0.9885675 ],\n",
              "       [0.99945277, 0.9994146 , 0.99947333, 0.99924916],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.99983627, 0.9998163 , 0.9998467 , 0.99971443],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99945277, 0.9994146 , 0.99947333, 0.99924916],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.989869  , 0.99030524, 0.9902013 , 0.9885675 ],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.999965  , 0.9999587 , 0.99996185, 0.999974  ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99997073, 0.99996495, 0.9999719 , 0.9999512 ],\n",
              "       [0.9999895 , 0.99998707, 0.9999889 , 0.9999901 ],\n",
              "       [0.99999684, 0.99999595, 0.9999968 , 0.99999624],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9999895 , 0.99998707, 0.9999889 , 0.9999901 ],\n",
              "       [0.9981728 , 0.9981361 , 0.99819237, 0.99802727],\n",
              "       [0.989869  , 0.99030524, 0.9902013 , 0.9885675 ],\n",
              "       [0.9999895 , 0.99998707, 0.9999889 , 0.9999901 ],\n",
              "       [0.99945277, 0.9994146 , 0.99947333, 0.99924916],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.9981728 , 0.9981361 , 0.99819237, 0.99802727],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99908525, 0.99903774, 0.99916273, 0.9983314 ],\n",
              "       [0.9999895 , 0.99998707, 0.9999889 , 0.9999901 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.99997073, 0.99996495, 0.9999719 , 0.9999512 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9999895 , 0.99998707, 0.9999889 , 0.9999901 ],\n",
              "       [0.99945277, 0.9994146 , 0.99947333, 0.99924916],\n",
              "       [0.999965  , 0.9999587 , 0.99996185, 0.999974  ],\n",
              "       [0.9981728 , 0.9981361 , 0.99819237, 0.99802727],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9981728 , 0.9981361 , 0.99819237, 0.99802727],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9981728 , 0.9981361 , 0.99819237, 0.99802727],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.999965  , 0.9999587 , 0.99996185, 0.999974  ],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.99997073, 0.99996495, 0.9999719 , 0.9999512 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.989869  , 0.99030524, 0.9902013 , 0.9885675 ],\n",
              "       [0.9999825 , 0.99997866, 0.99998236, 0.99997807],\n",
              "       [0.999965  , 0.9999587 , 0.99996185, 0.999974  ],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99983627, 0.9998163 , 0.9998467 , 0.99971443],\n",
              "       [0.999965  , 0.9999587 , 0.99996185, 0.999974  ],\n",
              "       [0.9999825 , 0.99997866, 0.99998236, 0.99997807],\n",
              "       [0.9999825 , 0.99997866, 0.99998236, 0.99997807],\n",
              "       [0.99999905, 0.99999875, 0.99999905, 0.99999857],\n",
              "       [0.99980426, 0.99978346, 0.9997916 , 0.9998481 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.99890655, 0.99886566, 0.9988625 , 0.9991121 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9969482 , 0.99693877, 0.99712867, 0.99562275],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.989869  , 0.99030524, 0.9902013 , 0.9885675 ],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.9981728 , 0.9981361 , 0.99819237, 0.99802727],\n",
              "       [0.993917  , 0.9940818 , 0.9938154 , 0.9948275 ],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.99990207, 0.9998883 , 0.99990356, 0.9998716 ],\n",
              "       [0.99999475, 0.9999933 , 0.9999949 , 0.99999166],\n",
              "       [0.99994147, 0.99993205, 0.9999394 , 0.99994224],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9981728 , 0.9981361 , 0.99819237, 0.99802727],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9996727 , 0.9996439 , 0.9996687 , 0.9996623 ],\n",
              "       [0.9999895 , 0.99998707, 0.9999889 , 0.9999901 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.evaluate(X_test, y_test2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeZGOC01nVGJ",
        "outputId": "83a82c11-1dc2-43aa-aa8f-c1d93139512d"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 95.7748  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.50829315185547"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r55XhwJOnVDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCC-6yKsnVA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZuou6_ynU--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XuOhvyL6nU8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}